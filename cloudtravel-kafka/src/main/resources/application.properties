application.name=cloudtravel-kafkaserver.port=8087# dubbo configdubbo.application.name=cloudtravel-webSocketdubbo.registry.protocol=zookeeperdubbo.registry.address=127.0.0.1:2181dubbo.protocol.name=dubbodubbo.protocol.port=20887dubbo.monitor.protocol=registry# dubbo.scan.base-packages=com.cloudtravel.consumer#连接zk的超时时间，msdubbo.registry.timeout=10000#启动应用时是否检查注册中心上有没有依赖的服务，默认truedubbo.consumer.check=false# ############### kafka configs start ################# kafka服务集群地址及端口spring.kafka.bootstrap-servers=127.0.0.1:9092#################kafka.producer的配置参数（开始）##################procedure要求leader在考虑完成请求之前收到的确认数，用于控制发送记录在服务端的持久化，其值可以为如下：#acks = 0 如果设置为零，则生产者将不会等待来自服务器的任何确认，该记录将立即添加到套接字缓冲区并视为已发送。#         在这种情况下，无法保证服务器已收到记录，并且重试配置将不会生效（因为客户端通常不会知道任何故障），为每条记录返回的偏移量始终设置为-1。#acks = 1 这意味着leader会将记录写入其本地日志，但无需等待所有副本服务器的完全确认即可做出回应，#         在这种情况下，如果leader在确认记录后立即失败，但在将数据复制到所有的副本服务器之前，则记录将会丢失。#acks = all 这意味着leader将等待完整的同步副本集以确认记录，这保证了只要至少一个同步副本服务器仍然存活，记录就不会丢失，#         这是最强有力的保证，这相当于acks = -1的设置。#可以设置的值为：all, -1, 0, 1spring.kafka.producer.acks=1# 重试次数:如果该值大于零时，表示启用重试失败的发送次数spring.kafka.producer.retries=1# 每当多个记录被发送到同一分区时，生产者将尝试将记录一起批量处理为更少的请求，# 这有助于提升客户端和服务器上的性能，此配置控制默认批量大小（以字节为单位），默认值为16384spring.kafka.producer.batch-size=16384# 提交延时 :  当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka## linger.ms为0表示每接收到一条消息就提交给kafka,这时候batch-size其实就没用了spring.kafka.producer.properties.linger.ms=0# 生产端缓冲区大小spring.kafka.producer.buffer-memory=33554432# Kafka提供的序列化和反序列化类spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializerspring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer# 自定义分区器类spring.kafka.producer.properties.partitioner.class=com.cloudtravel.kafkaLearn.config.CustomPartitioner#################kafka.producer的配置参数（结束）##################################kafka.consumer的配置参数（开始）################## 消费组idspring.kafka.consumer.properties.group.id=defaultConsumerGroup# 是否自动提交offset# true : 则消费者的偏移量将在后台定期提交.默认为truespring.kafka.consumer.enable-auto-commit=true# 如果'enable.auto.commit'为true，则消费者偏移自动提交给Kafka的频率（以毫秒为单位），默认值为5000。spring.kafka.consumer.auto.commit.interval.ms=5000# 当kafka中没有初始offset或者offset超出范围时将自动重置offset,取值范围如下:# earliest: 重置为分区中最小的offset# latest: 重置为分区中最新的offset# none : 只要有一个分区不存在已提交的offset,就抛出异常spring.kafka.consumer.auto-offset-reset=latest# 消费者连接的kafka主机IP及端口spring.kafka.consumer.bootstrap-servers=127.0.0.1:9092# 消费会话超时时间spring.kafka.consumer..properties.session.timeout.ms=10000# 消费请求超时时间spring.kafka.consumer.properties.request.timeout.ms=15000# 消费端的序列化及反序列化类spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializerspring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer# 消费端监听topic不存在时报错开关(false-关闭)spring.kafka.listener.missing-topics-fatal=false# 设置批量消费spring.kafka.listener.type=batch# 批量消费每次最多消费多少条消息spring.kafka.consumer.max-poll-records=50# 服务器返回消费端请求的最小字节数spring.kafka.consumer.fetch-min-size.byte=1#################kafka.consumer的配置参数（结束）#################spring.freemarker.checkTemplateLocation=false